{"title":"Lecture 03: Sampling and Simulation","markdown":{"yaml":{"title":"Lecture 03: Sampling and Simulation","date":"now","format":{"live-html":{"toc":true,"toc-location":"right","code-fold":true,"code-tools":true,"code-summary":"Code","code-block-name":"Code"}},"pyodide":{"packages":["matplotlib","numpy"]},"execute":{"warning":false}},"headingText":"Sampling from probability distributions","containsRefs":false,"markdown":"\n\n<!-- Back in Lecture 00, we mentioned the importance of thinking about the underlying processes that generate the data we observe. In this lecture, we are going to take a closer look at so-called \"data generating processes\" (DGPs) and how we model them in statistics and machine learning. -->\n\nNow that we have a good understanding of the basics of probability, we can start to explore how we deal with randomness computationally. \n\n<!-- Talk about what a sample is, IID sampling, sampling with replacement, sampling without replacement, -->\nA sample is a subset of data drawn from a more general population. That population can be thought of as a probability distribution -- this distribution essentially describes how likely you are to observe different values when you sample from it. \n\nWe will quickly review some important concepts related to sampling.\n\n### Independent and identically distributed (IID) sampling\n\nWhen we sample from a probability distribution, we often assume that the samples are independent and identically distributed (IID). This means that each sample is drawn from the same distribution and that the samples do not influence each other.\n\nCoin flips are a good example of IID sampling. If you flip a fair coin multiple times, each flip has the same probability of being heads or tails (this is the \"identically distributed\" part), and the outcome of one flip does not affect the outcome of another (this is the \"independent\" part). The same is true for rolling a die! \n\nWe often apply this concept to more complex random processes as well, where we do not have such a clear understanding of the underlying process. For example, if we are sampling the heights of people in a city, we might assume that each person's height is drawn from the same distribution (the distribution of heights in that city) and that one person's height does not affect another's. Whether or not the IID assumption holds in practice is an important question to consider when analyzing data -- for example, do you think that the heights of people in a family are independent of each other?\n\n\n\n\n\n### Sampling with and without replacement\n\nAnother important concept in sampling is the distinction between sampling with replacement and sampling without replacement.\n\n- **Sampling with replacement** means that after we draw a sample from the population, we put it back before drawing the next sample. This means that the same object / instance can be selected multiple times. \n\n- **Sampling without replacement** means that once we draw a sample, we do not put it back before drawing the next sample. This means that each individual can only be selected once. This can introduce dependencies between samples, as the population changes after each draw.\n\n\n## Simulating a random sample\n\nWe can simulate a random process by sampling from a corresponding probability distribution. \n\n::: {.callout-note}\nProgrammatic random sampling is not truly random, but rather \"pseudo-random.\" This means that the numbers generated are determined by an initial value called a \"seed\". If you use the same seed, you will get the same sequence of random numbers. This is useful for reproducibility in experiments and simulations.\n\nIf you don't specify a seed, the random number generator (RNG) will use a default seed that is typically based on the current date and time, which means that you will get different results each time you run the code.\n:::\n\nThere are built-in functions in many programming languages, including Python, that allow us to sample from common probability distributions. For example, in Python's NumPy library, we can use `numpy.random` module to sample from various distributions like uniform, normal, binomial, etc. \n\n\n::: {.callout-note title=\"Normal distribution\"}\nThe normal distribution is one of the most commonly used probability distributions in statistics. It is useful for modeling lots of real-world data, especially when the data tends to cluster around a mean (or average) value. The normal distribution is defined by two parameters: the mean (average) and the standard deviation (which measures how spread out the data is around the mean).\n:::\n\nFor example, to sample 100 values from a normal distribution with mean 0 and standard deviation 1, you can use:\n\n\nIf you have a dataset and you want to sample from it, you can use the `numpy.random.choice` function to randomly select elements from the dataset (with or without replacement). If your dataset is in a pandas DataFrame, you can also use the `sample` method to randomly select rows from the DataFrame.\n\nIf you want to sample from a custom distribution, you can also use the `numpy.random.choice` function to sample from a list of values with specified probabilities.\n\nHere's an example of how to sample 100 dice rolls with a rigged die that has a 50% chance of rolling a 6, and a 10% chance of rolling each of the other numbers (1-5):\n\n\n### Simulating more complex processes\n\nSometimes real-world processes are complex, and the samples we take are not independent. The simplest version of non-independence is sampling without replacement. \n\nConsider dealing poker hands from a standard deck of cards. When you deal a hand, you draw cards one at a time, and each card drawn affects the next card that can be drawn (because you do not put the card back into the deck).\n\nBut it can get even more complex than that. In many real-world scenarios, the process of generating data involves multiple steps or conditions that affect the outcome.\n\nIn these cases simulation might not be as straightforward as sampling from a single distribution (which takes just one or two lines of code). We then tend to write loops that simulate the process step by step, keeping track of the state of things as we go along.\n\nLet's consider an example of a musician busking for money in Rittenhouse Square. The musician's earnings might depend on various factors like the weather and and the number of passersby. To keep it simple, let's assume that the musician earns $3 for every passerby who stops to listen. Of course, not every passerby will stop -- let's pretend every passerby has the same 20% chance of stopping.\n\nThe musician might want to know how much money they can expect to earn in a day of busking. We can simulate this process by generating a random number of passersby and then calculating the earnings based on the stopping probability.\n\n:::{.callout-note title=\"Poisson distribution\"}\nThe Poisson distribution is commonly used to model the number of events that occur in a fixed interval of time or space, given a known average rate of occurrence. It assumes that the events occur independently and at a constant average rate. In our example, we can use the Poisson distribution to model the number of passersby in a given time period (e.g., one hour of busking).\n:::\n\n```{pyodide}\n#| exercise: average-weekly-busking\n#| caption: Simulate the expected earning of a busker in Rittenhouse Square over the course of a week.\n\nimport numpy as np\ndef busk_one_week(rng, n_days=7):\n    \"\"\"Simulate the earnings of a busker in Rittenhouse Square over the course of a week.\n    Args:\n        rng: A NumPy random number generator.\n        n_days: The number of days to simulate (default is 7).\n    Returns:\n        total_earnings: The total earnings over the week.\n    \"\"\"\n    # TODO: \n\nn_simulations = 1000\nrandom_seed = 33\n\n# TODO: Use the above function to simulate the expected earnings of a busker in Rittenhouse Square over the course of a week. Run the simulation 1000 times and calculate the average earnings over 1000 simulations. Hint: for loops are your friend here!\n\naverage_earnings = ...\naverage_earnings\n\n```\n\n\n::: {.solution exercise=\"average-weekly-busking\"}\n::: { .callout-tip collapse=\"false\"}\nThe key here is to re-use the logic of the weekly busking simulation in a loop that runs 1000 times. Each time we run the simulation, we get a different weekly outcome based on the random number generator. By averaging these outcomes, we can get a good estimate of the expected earnings over a week of busking. \n\n```python\nimport numpy as np\ndef busk_one_week(rng, n_days=7):\n    \"\"\"Simulate the earnings of a busker in Rittenhouse Square over the course of a week.\n    Args:\n        rng: A NumPy random number generator.\n        n_days: The number of days to simulate (default is 7).\n    Returns:\n        total_earnings: The total earnings over the week.\n    \"\"\"\n    rain_probabilities = rng.uniform(0., 0.7, size=n_days)\n\n    total_earnings = 0 # initialize a variable to keep track of total earnings\n    for day in range(n_days):\n        # For each day, decide if it rains based on the probability\n        did_it_rain = rng.binomial(n=1, p=rain_probabilities[day])\n        # Based on the outcome, the number of passersby changes\n        if did_it_rain:\n            passersby = rng.poisson(lam=50)  # fewer passersby when it rains\n        else:\n            passersby = rng.poisson(lam=200) # more passersby when it doesn't rain\n        # Simulate the number who stop to listen to the busker\n        listeners = rng.binomial(n=passersby, p=0.2)  # 20% of passersby stop\n        # Compute the busker's daily earnings\n        earnings = 3 * listeners  # $3 per listener\n\n        total_earnings += earnings\n\n    return total_earnings\n\nn_simulations = 1000\nrandom_seed = 33\n\nrng = np.random.default_rng(seed=random_seed)\n\n# Use the above function to simulate the expected earnings of a busker in Rittenhouse Square over the course of a week.\n# Run the simulation 1000 times and calculate the average earnings over 1000 simulations.\nearnings_by_week = [busk_one_week(rng) for _ in range(n_simulations)]\naverage_earnings = np.mean(earnings_by_week)\naverage_earnings\n```\n:::\n:::\n\n\n```{pyodide}\n#| exercise: average-weekly-busking\n#| check: true\n\n# Initialize feedback\nfeedback = {\"correct\": True, \"message\": \"Great job!\"}\n# Check if the average earnings are within a reasonable range\nif not random_seed == 33:\n    feedback[\"correct\"] = False\n    feedback[\"message\"] = \"Make sure to use the correct random seed for reproducibility.\"\nelif not (average_earnings != 89.307):\n    feedback[\"correct\"] = False\n    feedback[\"message\"] = \"The average earnings seem off. Check your simulation logic.\"\n\n```\n","srcMarkdownNoYaml":"\n\n<!-- Back in Lecture 00, we mentioned the importance of thinking about the underlying processes that generate the data we observe. In this lecture, we are going to take a closer look at so-called \"data generating processes\" (DGPs) and how we model them in statistics and machine learning. -->\n\nNow that we have a good understanding of the basics of probability, we can start to explore how we deal with randomness computationally. \n\n## Sampling from probability distributions\n<!-- Talk about what a sample is, IID sampling, sampling with replacement, sampling without replacement, -->\nA sample is a subset of data drawn from a more general population. That population can be thought of as a probability distribution -- this distribution essentially describes how likely you are to observe different values when you sample from it. \n\nWe will quickly review some important concepts related to sampling.\n\n### Independent and identically distributed (IID) sampling\n\nWhen we sample from a probability distribution, we often assume that the samples are independent and identically distributed (IID). This means that each sample is drawn from the same distribution and that the samples do not influence each other.\n\nCoin flips are a good example of IID sampling. If you flip a fair coin multiple times, each flip has the same probability of being heads or tails (this is the \"identically distributed\" part), and the outcome of one flip does not affect the outcome of another (this is the \"independent\" part). The same is true for rolling a die! \n\nWe often apply this concept to more complex random processes as well, where we do not have such a clear understanding of the underlying process. For example, if we are sampling the heights of people in a city, we might assume that each person's height is drawn from the same distribution (the distribution of heights in that city) and that one person's height does not affect another's. Whether or not the IID assumption holds in practice is an important question to consider when analyzing data -- for example, do you think that the heights of people in a family are independent of each other?\n\n\n\n\n\n### Sampling with and without replacement\n\nAnother important concept in sampling is the distinction between sampling with replacement and sampling without replacement.\n\n- **Sampling with replacement** means that after we draw a sample from the population, we put it back before drawing the next sample. This means that the same object / instance can be selected multiple times. \n\n- **Sampling without replacement** means that once we draw a sample, we do not put it back before drawing the next sample. This means that each individual can only be selected once. This can introduce dependencies between samples, as the population changes after each draw.\n\n\n## Simulating a random sample\n\nWe can simulate a random process by sampling from a corresponding probability distribution. \n\n::: {.callout-note}\nProgrammatic random sampling is not truly random, but rather \"pseudo-random.\" This means that the numbers generated are determined by an initial value called a \"seed\". If you use the same seed, you will get the same sequence of random numbers. This is useful for reproducibility in experiments and simulations.\n\nIf you don't specify a seed, the random number generator (RNG) will use a default seed that is typically based on the current date and time, which means that you will get different results each time you run the code.\n:::\n\nThere are built-in functions in many programming languages, including Python, that allow us to sample from common probability distributions. For example, in Python's NumPy library, we can use `numpy.random` module to sample from various distributions like uniform, normal, binomial, etc. \n\n\n::: {.callout-note title=\"Normal distribution\"}\nThe normal distribution is one of the most commonly used probability distributions in statistics. It is useful for modeling lots of real-world data, especially when the data tends to cluster around a mean (or average) value. The normal distribution is defined by two parameters: the mean (average) and the standard deviation (which measures how spread out the data is around the mean).\n:::\n\nFor example, to sample 100 values from a normal distribution with mean 0 and standard deviation 1, you can use:\n\n\nIf you have a dataset and you want to sample from it, you can use the `numpy.random.choice` function to randomly select elements from the dataset (with or without replacement). If your dataset is in a pandas DataFrame, you can also use the `sample` method to randomly select rows from the DataFrame.\n\nIf you want to sample from a custom distribution, you can also use the `numpy.random.choice` function to sample from a list of values with specified probabilities.\n\nHere's an example of how to sample 100 dice rolls with a rigged die that has a 50% chance of rolling a 6, and a 10% chance of rolling each of the other numbers (1-5):\n\n\n### Simulating more complex processes\n\nSometimes real-world processes are complex, and the samples we take are not independent. The simplest version of non-independence is sampling without replacement. \n\nConsider dealing poker hands from a standard deck of cards. When you deal a hand, you draw cards one at a time, and each card drawn affects the next card that can be drawn (because you do not put the card back into the deck).\n\nBut it can get even more complex than that. In many real-world scenarios, the process of generating data involves multiple steps or conditions that affect the outcome.\n\nIn these cases simulation might not be as straightforward as sampling from a single distribution (which takes just one or two lines of code). We then tend to write loops that simulate the process step by step, keeping track of the state of things as we go along.\n\nLet's consider an example of a musician busking for money in Rittenhouse Square. The musician's earnings might depend on various factors like the weather and and the number of passersby. To keep it simple, let's assume that the musician earns $3 for every passerby who stops to listen. Of course, not every passerby will stop -- let's pretend every passerby has the same 20% chance of stopping.\n\nThe musician might want to know how much money they can expect to earn in a day of busking. We can simulate this process by generating a random number of passersby and then calculating the earnings based on the stopping probability.\n\n:::{.callout-note title=\"Poisson distribution\"}\nThe Poisson distribution is commonly used to model the number of events that occur in a fixed interval of time or space, given a known average rate of occurrence. It assumes that the events occur independently and at a constant average rate. In our example, we can use the Poisson distribution to model the number of passersby in a given time period (e.g., one hour of busking).\n:::\n\n```{pyodide}\n#| exercise: average-weekly-busking\n#| caption: Simulate the expected earning of a busker in Rittenhouse Square over the course of a week.\n\nimport numpy as np\ndef busk_one_week(rng, n_days=7):\n    \"\"\"Simulate the earnings of a busker in Rittenhouse Square over the course of a week.\n    Args:\n        rng: A NumPy random number generator.\n        n_days: The number of days to simulate (default is 7).\n    Returns:\n        total_earnings: The total earnings over the week.\n    \"\"\"\n    # TODO: \n\nn_simulations = 1000\nrandom_seed = 33\n\n# TODO: Use the above function to simulate the expected earnings of a busker in Rittenhouse Square over the course of a week. Run the simulation 1000 times and calculate the average earnings over 1000 simulations. Hint: for loops are your friend here!\n\naverage_earnings = ...\naverage_earnings\n\n```\n\n\n::: {.solution exercise=\"average-weekly-busking\"}\n::: { .callout-tip collapse=\"false\"}\nThe key here is to re-use the logic of the weekly busking simulation in a loop that runs 1000 times. Each time we run the simulation, we get a different weekly outcome based on the random number generator. By averaging these outcomes, we can get a good estimate of the expected earnings over a week of busking. \n\n```python\nimport numpy as np\ndef busk_one_week(rng, n_days=7):\n    \"\"\"Simulate the earnings of a busker in Rittenhouse Square over the course of a week.\n    Args:\n        rng: A NumPy random number generator.\n        n_days: The number of days to simulate (default is 7).\n    Returns:\n        total_earnings: The total earnings over the week.\n    \"\"\"\n    rain_probabilities = rng.uniform(0., 0.7, size=n_days)\n\n    total_earnings = 0 # initialize a variable to keep track of total earnings\n    for day in range(n_days):\n        # For each day, decide if it rains based on the probability\n        did_it_rain = rng.binomial(n=1, p=rain_probabilities[day])\n        # Based on the outcome, the number of passersby changes\n        if did_it_rain:\n            passersby = rng.poisson(lam=50)  # fewer passersby when it rains\n        else:\n            passersby = rng.poisson(lam=200) # more passersby when it doesn't rain\n        # Simulate the number who stop to listen to the busker\n        listeners = rng.binomial(n=passersby, p=0.2)  # 20% of passersby stop\n        # Compute the busker's daily earnings\n        earnings = 3 * listeners  # $3 per listener\n\n        total_earnings += earnings\n\n    return total_earnings\n\nn_simulations = 1000\nrandom_seed = 33\n\nrng = np.random.default_rng(seed=random_seed)\n\n# Use the above function to simulate the expected earnings of a busker in Rittenhouse Square over the course of a week.\n# Run the simulation 1000 times and calculate the average earnings over 1000 simulations.\nearnings_by_week = [busk_one_week(rng) for _ in range(n_simulations)]\naverage_earnings = np.mean(earnings_by_week)\naverage_earnings\n```\n:::\n:::\n\n\n```{pyodide}\n#| exercise: average-weekly-busking\n#| check: true\n\n# Initialize feedback\nfeedback = {\"correct\": True, \"message\": \"Great job!\"}\n# Check if the average earnings are within a reasonable range\nif not random_seed == 33:\n    feedback[\"correct\"] = False\n    feedback[\"message\"] = \"Make sure to use the correct random seed for reproducibility.\"\nelif not (average_earnings != 89.307):\n    feedback[\"correct\"] = False\n    feedback[\"message\"] = \"The average earnings seem off. Check your simulation logic.\"\n\n```\n"},"formats":{"live-html":{"identifier":{"display-name":"HTML","target-format":"live-html","base-format":"html","extension-name":"live"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"shortcodes":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["/Users/jrudoler/Documents/teaching/understanding-uncertainty/_extensions/r-wasm/live/live.lua"],"toc":true,"output-file":"lecture-03.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","ojs-engine":true,"revealjs-plugins":[],"theme":{"light":"flatly","dark":"darkly"},"title":"Lecture 03: Sampling and Simulation","date":"now","pyodide":{"packages":["matplotlib","numpy"]},"toc-location":"right","code-summary":"Code","code-block-name":"Code"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["live-html"]}