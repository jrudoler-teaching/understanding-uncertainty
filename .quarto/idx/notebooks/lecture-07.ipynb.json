{"title":"Lecture 07: Permutation and Computational Hypothesis Testing","markdown":{"yaml":{"title":"Lecture 07: Permutation and Computational Hypothesis Testing","date":"now","format":{"live-html":{"toc":true,"toc-location":"right","code-fold":true,"code-tools":true,"code-summary":"Code","code-block-name":"Code"}},"pyodide":{"packages":["matplotlib","numpy"]},"execute":{"warning":false}},"headingText":"Permutation Tests","containsRefs":false,"markdown":"\n\n\nThere is one more frequently applicable sampling-based method that is super helpful in statistical inference: permutation (or randomization) tests.\n\nPermutation tests, like the bootstrap, are non-parametric -- meaning they do not rely on assumptions about the underlying distribution of the data. Like the bootstrap, permutation tests rely on resampling -- only instead of resampling with replacement, we resample without replacement.\n\nSay we have two samples, $X$ and $Y$, and we want to test if they have different underlying distributions (e.g. different means). Then, our null hypothesis ($H_0$) is that the two samples are drawn from the same distribution.\n\nSo, we can combine the two samples into one larger sample, $Z = X \\cup Y$, and then randomly split $Z$ into two new samples, $X'$ and $Y'$, of the same size as the original samples. We can then compute the test statistic (e.g. the difference in means) for the new samples and repeat this process many times to build a distribution of test statistics under the null hypothesis.\n\nThe only assumption we need to make is that the two samples are **exchangeable** under the null hypothesis. This means that, if the null hypothesis is true, the two samples could be shuffled without changing the underlying distribution.\n\n`np.random.permutation` is a useful function for this. It randomly permutes the elements of an array, which we can use to create our new samples. Let's define a function to perform a permutation test for \n\nWe can apply this to our NBA data to test if SGA and Giannis have different scoring rates. This is quite similar to the bootstrap hypothesis test we did in the previous lecture, but instead of resampling with replacement, we will resample without replacement.\n\nBoth versions work, but the permutation test tends to be more powerful. \n\n:::{.callout-note title=\"Statistical Power\"}\nPower\n: The probability of correctly rejecting the null hypothesis when it is false. \n\nA more \"powerful\" test is more likely to detect a true effect. The power of a test is often written as $1 - \\beta$, where $\\beta$ is the probability of a Type II error (failing to reject the null hypothesis when it is false).\n\nWe usually want our tests to have high power, so we can detect true effects when they exist. We try to balance this against the risk of **falsely** rejecting the null hypothesis (Type I error) when it is actually true.\n:::\n\n\n## There is really only one test!\n\nThe more statistics you learn and the more you are exposed to work in quantitative fields, the more you will see a wide variety of complicated statistical techniques and methods. \n\nUltimately they all represent the same process:\n1. Compute a test statistic on the observed data.\n2. Choose a null hypothesis / model. Either specify the null distribution explicitly or use a simulation-based method to generate a distribution of test statistics under the null hypothesis.\n3. Compute a p-value by comparing the observed test statistic to the distribution of test statistics under the null hypothesis. \n\nMost of the literature in classical statistics focuses on mathematically deriving analytical solutions for 2 and 3. All of the fancy named statistical tests you see are variations with different test statistics and null hypotheses. \n\nCheck out [this blog post](https://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html) by Allen Downey for more on this idea and explanation of the advantages of simulation-based methods for hypothesis testing.\n\n### Example: Two-sample t-test\n\nOne of the most common statistical tests is the independent two-sample $t$-test, which tests if two independent samples have different means. This is used in many fields, including psychology, medicine, and social sciences -- basically anywhere you want to compare two groups.\n\nRemembering the $t$-test is not an important point of this course -- we introduce it here because it is used so frequently in practice that it is worth understanding the basic idea behind it (and that it is just a special case of the general hypothesis testing framework we have been discussing).\n\nWe learned already that (by the Central Limit Theorem) as the sample size increases, the sampling distribution of the sample mean becomes approximately normal, even if the underlying distribution is not normal. The *exact* distribution of the sample mean, however, is called the **t-distribution**. It is quite like the normal distribution, but has heavier tails (more likely to produce extreme values). See the plots below for an illustration of how the t-distribution converges to the standard normal distribution as the sample size increases.\n\nLet's create two independent samples from uniform distributions with different means and equal variance. We'll perform a two-sample t-test to see if they are significantly different. In other words, we will test the null hypothesis that the two samples have the same mean against the alternative hypothesis that they have different means.\n\nWe'll use the built-in `scipy.stats.ttest_ind` function to perform the t-test, but we will also manually compute the t-statistic and p-value to illustrate the process. We will also sample from the t-distribution to compare our results. Finally, we will perform a permutation test to see how it compares.\n\nAll of these results are quite similar! It's not a coincidence -- they are all effectively the same test. We're comparing the observed t-statistic to the distribution of t-statistics under the null hypothesis that the two samples are drawn from the same distribution.\n\nThis might be easier to appreciate visually:\n\nSee how close the sampling distributions are to the theoretical t-distribution? This is why all the tests are so similar.\n\n\n","srcMarkdownNoYaml":"\n\n## Permutation Tests\n\nThere is one more frequently applicable sampling-based method that is super helpful in statistical inference: permutation (or randomization) tests.\n\nPermutation tests, like the bootstrap, are non-parametric -- meaning they do not rely on assumptions about the underlying distribution of the data. Like the bootstrap, permutation tests rely on resampling -- only instead of resampling with replacement, we resample without replacement.\n\nSay we have two samples, $X$ and $Y$, and we want to test if they have different underlying distributions (e.g. different means). Then, our null hypothesis ($H_0$) is that the two samples are drawn from the same distribution.\n\nSo, we can combine the two samples into one larger sample, $Z = X \\cup Y$, and then randomly split $Z$ into two new samples, $X'$ and $Y'$, of the same size as the original samples. We can then compute the test statistic (e.g. the difference in means) for the new samples and repeat this process many times to build a distribution of test statistics under the null hypothesis.\n\nThe only assumption we need to make is that the two samples are **exchangeable** under the null hypothesis. This means that, if the null hypothesis is true, the two samples could be shuffled without changing the underlying distribution.\n\n`np.random.permutation` is a useful function for this. It randomly permutes the elements of an array, which we can use to create our new samples. Let's define a function to perform a permutation test for \n\nWe can apply this to our NBA data to test if SGA and Giannis have different scoring rates. This is quite similar to the bootstrap hypothesis test we did in the previous lecture, but instead of resampling with replacement, we will resample without replacement.\n\nBoth versions work, but the permutation test tends to be more powerful. \n\n:::{.callout-note title=\"Statistical Power\"}\nPower\n: The probability of correctly rejecting the null hypothesis when it is false. \n\nA more \"powerful\" test is more likely to detect a true effect. The power of a test is often written as $1 - \\beta$, where $\\beta$ is the probability of a Type II error (failing to reject the null hypothesis when it is false).\n\nWe usually want our tests to have high power, so we can detect true effects when they exist. We try to balance this against the risk of **falsely** rejecting the null hypothesis (Type I error) when it is actually true.\n:::\n\n\n## There is really only one test!\n\nThe more statistics you learn and the more you are exposed to work in quantitative fields, the more you will see a wide variety of complicated statistical techniques and methods. \n\nUltimately they all represent the same process:\n1. Compute a test statistic on the observed data.\n2. Choose a null hypothesis / model. Either specify the null distribution explicitly or use a simulation-based method to generate a distribution of test statistics under the null hypothesis.\n3. Compute a p-value by comparing the observed test statistic to the distribution of test statistics under the null hypothesis. \n\nMost of the literature in classical statistics focuses on mathematically deriving analytical solutions for 2 and 3. All of the fancy named statistical tests you see are variations with different test statistics and null hypotheses. \n\nCheck out [this blog post](https://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html) by Allen Downey for more on this idea and explanation of the advantages of simulation-based methods for hypothesis testing.\n\n### Example: Two-sample t-test\n\nOne of the most common statistical tests is the independent two-sample $t$-test, which tests if two independent samples have different means. This is used in many fields, including psychology, medicine, and social sciences -- basically anywhere you want to compare two groups.\n\nRemembering the $t$-test is not an important point of this course -- we introduce it here because it is used so frequently in practice that it is worth understanding the basic idea behind it (and that it is just a special case of the general hypothesis testing framework we have been discussing).\n\nWe learned already that (by the Central Limit Theorem) as the sample size increases, the sampling distribution of the sample mean becomes approximately normal, even if the underlying distribution is not normal. The *exact* distribution of the sample mean, however, is called the **t-distribution**. It is quite like the normal distribution, but has heavier tails (more likely to produce extreme values). See the plots below for an illustration of how the t-distribution converges to the standard normal distribution as the sample size increases.\n\nLet's create two independent samples from uniform distributions with different means and equal variance. We'll perform a two-sample t-test to see if they are significantly different. In other words, we will test the null hypothesis that the two samples have the same mean against the alternative hypothesis that they have different means.\n\nWe'll use the built-in `scipy.stats.ttest_ind` function to perform the t-test, but we will also manually compute the t-statistic and p-value to illustrate the process. We will also sample from the t-distribution to compare our results. Finally, we will perform a permutation test to see how it compares.\n\nAll of these results are quite similar! It's not a coincidence -- they are all effectively the same test. We're comparing the observed t-statistic to the distribution of t-statistics under the null hypothesis that the two samples are drawn from the same distribution.\n\nThis might be easier to appreciate visually:\n\nSee how close the sampling distributions are to the theoretical t-distribution? This is why all the tests are so similar.\n\n\n"},"formats":{"live-html":{"identifier":{"display-name":"HTML","target-format":"live-html","base-format":"html","extension-name":"live"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"shortcodes":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["/Users/jrudoler/Documents/teaching/understanding-uncertainty/_extensions/r-wasm/live/live.lua","shinylive"],"toc":true,"output-file":"lecture-07.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","ojs-engine":true,"revealjs-plugins":[],"theme":{"light":"flatly","dark":"darkly"},"title":"Lecture 07: Permutation and Computational Hypothesis Testing","date":"now","pyodide":{"packages":["matplotlib","numpy"]},"toc-location":"right","code-summary":"Code","code-block-name":"Code"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["live-html"]}