{
 "cells": [
  {
   "cell_type": "raw",
   "id": "582c1769",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Lecture 06: Permutation and Computational Hypothesis Testing\"\n",
    "date: \"now\"\n",
    "format: \n",
    "    live-html:\n",
    "        toc: true\n",
    "        toc-location: right\n",
    "        code-fold: true\n",
    "        code-tools: true\n",
    "        code-summary: \"Code\"\n",
    "        code-block-name: \"Code\"\n",
    "pyodide:\n",
    "  packages:\n",
    "    - matplotlib\n",
    "    - numpy\n",
    "execute:\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adca78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hidden: true\n",
    "# | echo: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# some personal style settings to make the plots look nice\n",
    "# and save some space in the notebook\n",
    "plt.style.use(\"../style.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42dd3d4",
   "metadata": {},
   "source": [
    "## Permutation Tests\n",
    "\n",
    "There is one more frequently applicable sampling-based method that is super helpful in statistical inference: permutation (or randomization) tests.\n",
    "\n",
    "Permutation tests, like the bootstrap, are non-parametric -- meaning they do not rely on assumptions about the underlying distribution of the data. Like the bootstrap, permutation tests rely on resampling -- only instead of resampling with replacement, we resample without replacement.\n",
    "\n",
    "Say we have two samples, $X$ and $Y$, and we want to test if they have different underlying distributions (e.g. different means). Then, our null hypothesis ($H_0$) is that the two samples are drawn from the same distribution.\n",
    "\n",
    "So, we can combine the two samples into one larger sample, $Z = X \\cup Y$, and then randomly split $Z$ into two new samples, $X'$ and $Y'$, of the same size as the original samples. We can then compute the test statistic (e.g. the difference in means) for the new samples and repeat this process many times to build a distribution of test statistics under the null hypothesis.\n",
    "\n",
    "The only assumption we need to make is that the two samples are **exchangeable** under the null hypothesis. This means that, if the null hypothesis is true, the two samples could be shuffled without changing the underlying distribution.\n",
    "\n",
    "`np.random.permutation` is a useful function for this. It randomly permutes the elements of an array, which we can use to create our new samples. Let's define a function to perform a permutation test for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "def permutation_test(test_func, x, y, num_permutations=10000, rng=None):\n",
    "    # Compute the observed test statistic\n",
    "    observed_stat = test_func(x, y)\n",
    "\n",
    "    # Combine the two samples\n",
    "    combined = np.concatenate([x, y])\n",
    "    count = 0\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    for _ in range(num_permutations):\n",
    "        # Permute the combined array\n",
    "        permuted = rng.permutation(combined)\n",
    "\n",
    "        # Split the permuted array into two new samples\n",
    "        x_perm = permuted[:len(x)]\n",
    "        y_perm = permuted[len(x):]\n",
    "\n",
    "        # Compute the test statistic for the permuted samples\n",
    "        permuted_stat = test_func(x_perm, y_perm)\n",
    "\n",
    "        # Compare the permuted statistic to the observed statistic\n",
    "        if permuted_stat >= observed_stat:\n",
    "            count += 1\n",
    "\n",
    "    # Compute the p-value\n",
    "    p_value = count / num_permutations\n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ef017",
   "metadata": {},
   "source": [
    "We can apply this to our NBA data to test if SGA and Giannis have different scoring rates. This is quite similar to the bootstrap hypothesis test we did in the previous lecture, but instead of resampling with replacement, we will resample without replacement.\n",
    "\n",
    "Both versions work, but the permutation test tends to be more powerful. \n",
    "\n",
    ":::{.callout-note title=\"Statistical Power\"}\n",
    "Power\n",
    ": The probability of correctly rejecting the null hypothesis when it is false. \n",
    "\n",
    "A more \"powerful\" test is more likely to detect a true effect. The power of a test is often written as $1 - \\beta$, where $\\beta$ is the probability of a Type II error (failing to reject the null hypothesis when it is false).\n",
    "\n",
    "We usually want our tests to have high power, so we can detect true effects when they exist. We try to balance this against the risk of **falsely** rejecting the null hypothesis (Type I error) when it is actually true.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f203285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value for the hypothesis that SGA scores more points than Giannis: 0.0336\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "### Data import and preparation ###\n",
    "sga_df = pd.read_csv(\"../data/sga-stats-24-25.csv\")\n",
    "giannis_df = pd.read_csv(\"../data/giannis-stats-24-25.csv\")\n",
    "# combine the dataframes and clean up the data\n",
    "sga_df[\"player\"] = \"Shai Gilgeous-Alexander\"\n",
    "giannis_df[\"player\"] = \"Giannis Antetokounmpo\"\n",
    "compare_df = pd.concat([sga_df, giannis_df], ignore_index=True)\n",
    "# filter out rows where the player did not play or was inactive\n",
    "compare_df = compare_df.replace(\n",
    "    {\"Did Not Dress\": np.nan, \"Inactive\": np.nan, \"Did Not Play\": np.nan, \"\": np.nan}\n",
    ")\n",
    "compare_df.dropna(subset=[\"PTS\"], inplace=True)\n",
    "# convert PTS to float/numeric and Date to datetime\n",
    "compare_df[\"PTS\"] = compare_df[\"PTS\"].astype(float)\n",
    "compare_df[\"Date\"] = pd.to_datetime(compare_df[\"Date\"])\n",
    "\n",
    "rng = np.random.default_rng(42) \n",
    "# run the permutation test\n",
    "p_value = permutation_test(\n",
    "    lambda x, y: np.mean(x) - np.mean(y), # lambda functions can be used inline without naming the function\n",
    "    compare_df[compare_df[\"player\"] == \"Shai Gilgeous-Alexander\"][\"PTS\"],\n",
    "    compare_df[compare_df[\"player\"] == \"Giannis Antetokounmpo\"][\"PTS\"],\n",
    "    rng=rng\n",
    ")\n",
    "print(\n",
    "    f\"P-value for the hypothesis that SGA scores more points than Giannis: {p_value:.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd6897",
   "metadata": {},
   "source": [
    "## There is really only one test!\n",
    "\n",
    "The more statistics you learn and the more you are exposed to work in quantitative fields, the more you will see a wide variety of complicated statistical techniques and methods. \n",
    "\n",
    "Ultimately they all represent the same process:\n",
    "1. Compute a test statistic on the observed data.\n",
    "2. Choose a null hypothesis / model. Either specify the null distribution explicitly or use a simulation-based method to generate a distribution of test statistics under the null hypothesis.\n",
    "3. Compute a p-value by comparing the observed test statistic to the distribution of test statistics under the null hypothesis. \n",
    "\n",
    "Most of the literature in classical statistics focuses on mathematically deriving analytical solutions for 2 and 3. They \n",
    "\n",
    "Check out [this blog post](https://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html) by Allen Downey for more on this idea and explanation of the advantages of simulation-based methods for hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0a2f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "understanding-uncertainty-vC6A7Gjf-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
