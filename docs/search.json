[
  {
    "objectID": "assignments/assignment-00.html",
    "href": "assignments/assignment-00.html",
    "title": "Assignment 00",
    "section": "",
    "text": "print(\"Hello, World!\")\n\nHello, World!"
  },
  {
    "objectID": "notebooks/lecture-02.html",
    "href": "notebooks/lecture-02.html",
    "title": "Lecture 02: Probability and Random Variables",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathbb{P}}\n\\]",
    "crumbs": [
      "Home",
      "Lecture 02: Probability and Random Variables"
    ]
  },
  {
    "objectID": "notebooks/lecture-02.html#probability",
    "href": "notebooks/lecture-02.html#probability",
    "title": "Lecture 02: Probability and Random Variables",
    "section": "Probability",
    "text": "Probability\nMost of you are probably familiar with the basic intuition of probability: essentially it measures how likely an event is to occur.\nIn mathematical terms, the probability \\(\\P\\) of an event \\(A\\) is defined as:\n\\[\\begin{align*}\n\\P(A) &= \\frac{\\text{ \\# of outcomes where } A \\text{ occurs}}{\\text{ total \\# of outcomes}} \\\\\n\\end{align*}\\]\nBy definition this quantity cannot be negative (\\(\\P(A) = 0\\) means \\(A\\) never occurs), and it must be less than or equal to 1 (\\(\\P(A) = 1\\) means \\(A\\) always occurs).\nThe classical example of probability is flipping a coin. When you flip a fair coin, there are two possible outcomes: heads (\\(H\\)) and tails (\\(T\\)). If we let \\(A\\) be the event that the coin lands on heads, then we can compute the probability of \\(A\\) as follows:\n\\[\\begin{align*}\n\\P(\\text{H}) &= \\frac{\\text{ \\# of heads}}{\\text{ total \\# of outcomes}} \\\\\n      &= \\frac{1}{2} \\\\\n\\end{align*}\\]\nThis matches our intuition that a fair coin has a 50% chance of landing on heads.\n\nProbability of multiple events\nBut what if we flip the coin twice? Now there are four possible outcomes: \\(HH\\), \\(HT\\), \\(TH\\), and \\(TT\\).\nIf we let \\(B\\) be the event that at least one coin lands on heads, we can compute the probability of \\(B\\) as follows: \\[\\begin{align*}\n\\P(B) &= \\frac{\\text{ \\# of outcomes with at least one head}}{\\text{ total \\# of outcomes}} \\\\\n      &= \\frac{|\\{HH, HT, TH\\}|}{|\\{HH, HT, TH, TT\\}|} \\\\\n      &= \\frac{3}{4} \\\\\n\\end{align*}\\]\n\n\nAddition and multiplication rules (and / or)\nWhat is the probability of getting heads on the first flip AND the second flip (i.e., the event \\(C = \\{HH\\}\\))?\nWell, there is only one outcome where both flips are heads, and there are still four total outcomes. So using our initial approach we know that \\(\\P(C) = \\P (H_1 ~\\text{and}~ H_2) = \\frac{1}{4}\\).\nWhat about the probability of getting heads on the first flip OR the second flip? This is actually the same event as \\(B\\) above, so we can use the same calculation: \\(\\P(B) = \\P(H_1 ~\\text{or}~ H_2) = \\frac{3}{4}\\).\n\n\n\n\n\n\nNote on notation\n\n\n\n\n\nIn the above, we used \\(H_1\\) and \\(H_2\\) to denote heads on the first and second flips, respectively. The notation \\(H_1 ~\\text{and}~ H_2\\) means both flips are heads, while \\(H_1 ~\\text{or}~ H_2\\) means at least one flip is heads.\nIn probability theory, we often use the symbols \\(\\cap\\) and \\(\\cup\\) to denote “and” and “or” respectively. So we could also write \\(\\P(H_1 \\cap H_2)\\) for the probability of both flips being heads, and \\(\\P(H_1 \\cup H_2)\\) for the probability of at least one flip being heads. Technically, this is set notation where \\(\\cap\\) means intersection (the event where both \\(H_1\\) and \\(H_2\\) occur), while \\(\\cup\\) means union (the event where either \\(H_1\\) or \\(H_2\\) occurs).\n\n\n\nThere are some important rules for calculating probabilities of multiple events. In particular, if you hve two events \\(A\\) and \\(B\\), the following rules hold:\n\nAddition rule: For any two events \\(A\\) and \\(B\\), the probability of either \\(A\\) or \\(B\\) occurring is given by: \\[\n\\P(A \\cup B) = \\P(A) + \\P(B) - \\P(A \\cap B)\n\\] This last term, \\(\\P(A \\cap B)\\), is necessary to avoid double counting the outcomes where both \\(A\\) and \\(B\\) occur.\nNote that if \\(A\\) and \\(B\\) are mutually exclusive (i.e., they cannot both occur at the same time), then \\(\\P(A \\cap B) = 0\\), and the formula simplifies to: \\[  \\P(A \\cup B) = \\P(A) + \\P(B)\\]\n\n\n\n\n\n\n\nVisualizing sets of events\n\n\n\n\n\nThe following image illustrates the addition rule for two events \\(A\\) and \\(B\\) using a Venn diagram. \n\n\n\n\nMultiplication rule: For any two events \\(A\\) and \\(B\\), the probability of both \\(A\\) and \\(B\\) occurring is given by: \\[\\P(A \\cap B) = \\P(A) \\cdot \\P(B | A)\\] where \\(\\P(B | A)\\) is the conditional probability of \\(B\\) given that \\(A\\) has occurred. This means you first consider the outcomes where \\(A\\) occurs, and then look at the probability of \\(B\\) within that subset.\n\n\n\n\n\n\n\nConditional probability\n\n\n\n\n\nThe notation \\(\\P(B | A)\\) is read as “the probability of \\(B\\) given \\(A\\)”. It represents the probability of event \\(B\\) occurring under the condition that event \\(A\\) has already occurred.\nWe make these adjustments in our heads all of the time. For example, you might expect that it is more likely I will buy ice cream if it is hot outside. In this case, the event \\(A\\) is “it is hot outside”, and the event \\(B\\) is “I buy ice cream”. The conditional probability \\(\\P(B | A)\\) would be higher than \\(\\P(B)\\) on a typical day.\nLet’s think about this in the context of our coin flips. If we know that the first flip is heads (\\(H_1\\)), then only two outcomes are possible (\\(HH\\) and \\(HT\\)) instead of four (\\(HH\\), \\(HT\\), \\(TH\\), \\(TT\\)).\nSo the conditional probability \\(\\P(H_2 | H_1)\\), which is the probability of the second flip being heads given that the first flip was heads, is: \\[\\begin{align*}\n\\P(H_2 | H_1) &= \\frac{\\text{ \\# of outcomes where } H_2 \\text{ occurs and } H_1 \\text{ has occurred}}{\\text{ total \\# of outcomes where } H_1 \\text{ has occurred}} \\\\\n&= \\frac{|\\{HH\\}|}{|\\{HH, HT\\}|} \\\\\n&= \\frac{1}{2} \\\\\n\\end{align*}\\]\n\n\n\nThe multiplication rule helps us calculate the probability of multiple events happening, as long as we know how one event affects the other (i.e., the conditional probability). An example will help clarify make this concrete.\nConsider a deck of cards (52 cards total, 13 of each suit). I might ask you, “What is the probability of drawing a club on the first draw and a club on the second draw? (Assuming you do not replace the first card.)”\n\n\n\n\n\n\n\n\nYou will see more complicated examples of probability in the assignment for this lecture, but the basic idea is the same: you count the number of outcomes where the event occurs, and divide by the total number of outcomes.\n\n\nIndependence\nTwo events \\(A\\) and \\(B\\) are said to be independent if the occurrence of one does not affect the probability of the other.\nHow does this relate to the multiplication rule? If \\(A\\) and \\(B\\) are independent, then the conditional probability \\(\\P(B | A)\\) is simply \\(\\P(B)\\). That is, knowing that \\(A\\) has occurred does not change the probability of \\(B\\) occurring.\nThis means that for independent events, the multiplication rule simplifies to:\n\\[\\P(A \\cap B) = \\P(A) \\cdot \\P(B)\\]\nOur coin flip example illustrates this nicely. If we flip a fair coin twice, the outcome of the first flip does not affect the outcome of the second flip. Therefore, the two events (the first flip being heads and the second flip being heads) are independent. So the probability of both flips being heads is simply \\(\\P(H_1 \\cap H_2) = \\P(H_1) \\cdot \\P(H_2) = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4}\\).",
    "crumbs": [
      "Home",
      "Lecture 02: Probability and Random Variables"
    ]
  },
  {
    "objectID": "notebooks/lecture-02.html#probability-functions",
    "href": "notebooks/lecture-02.html#probability-functions",
    "title": "Lecture 02: Probability and Random Variables",
    "section": "Probability functions",
    "text": "Probability functions\nThinking about probability in terms of counting outcomes is useful, and it is always a good idea to keep that intuition in mind if you ever get stuck.\nHowever, it is often more convenient to work with probability functions. A probability function assigns a probability to each possible outcome. In order to define a probability function, we need to be able to assign numerical values to each outcome. For example, if we have a fair coin, we can define a probability function \\(f\\) as follows: \\[\nf(x) = \\begin{cases}\n    \\frac{1}{2} & \\text{if } x = 0 \\text{ (heads)} \\\\\n    \\frac{1}{2} & \\text{if } x = 1 \\text{ (tails)} \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\] where \\(x\\) is the outcome of the coin flip (0 for heads, 1 for tails).\n\n\n\n\n\n\nFunctions map inputs to outputs\n\n\n\n\n\nFunctions are just a “map” that tells you what output to expect for each input. A probability function is a special type of function that maps inputs to probabilities in the range \\([0, 1]\\).\n\n\n\nThis might seem a bit redundant because we’re just presenting the same information in a new format. However, one reason that probability functions are important is that they allow us to concisely describe the probability of outcomes that have many possible values.\nFor example, if we have a die with six sides, we can define a probability function \\(f\\) as follows: \\[\nf(x) = \\begin{cases}\n    \\frac{1}{6} & \\text{if } x = 1, 2, 3, 4, 5, 6 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\]\nBut we can also use the same function to describe the probability of rolling a die with any number of sides. For example, if we have a die with \\(k\\) sides, we can define a probability function \\(f\\) as follows:\n\\[\nf(x) = \\begin{cases}\n    \\frac{1}{k} & \\text{if } x = 1, 2, \\ldots, k \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\] This is much more concise than writing out the probability for each possible outcome, and it allows us to easily generalize to any number of sides.\n\n\n\n\n\n\n\n\n\ndef f(x, k):\n    if 1 &lt;= x &lt;= k:\n        return 1 / k\n    else:\n        return 0\n\nCode\n\ndef f(x, k):\n    if 1 &lt;= x &lt;= k:\n        return 1 / k\n    else:\n        return 0",
    "crumbs": [
      "Home",
      "Lecture 02: Probability and Random Variables"
    ]
  },
  {
    "objectID": "notebooks/lecture-02.html#random-variables",
    "href": "notebooks/lecture-02.html#random-variables",
    "title": "Lecture 02: Probability and Random Variables",
    "section": "Random Variables",
    "text": "Random Variables\nA random variable is a quantity that can take on different values based on the outcome of a random event. It might be a discrete variable (like the outcome of a coin flip) or a continuous variable (like the height of a person). Basically it is an quantity that has randomness associated with it. We denote random variables with capital letters, like \\(X\\) or \\(Y\\). The specific values that a random variable can take on in a particular instance are usually denoted with lowercase letters, like \\(x\\) or \\(y\\).\nWe use probability functions to describe the probabilities associated with random variables. Specifically, a probability function \\(f\\) for a random variable \\(X\\) gives the probability that \\(X\\) takes on a specific value \\(x\\).\nFor example, let \\(X\\) be a random variable that represents the outcome of flipping a fair coin. The probability function for \\(X\\) would be: \\[\nf(x) = \\P (X = x) = \\begin{cases}\n    \\frac{1}{2} & \\text{if } x = 0 \\text{ (heads)} \\\\\n    \\frac{1}{2} & \\text{if } x = 1 \\text{ (tails)} \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\n\n\n\nBernoulli random variable\n\n\n\n\n\nThe above is an example of a Bernoulli random variable, which takes on the value 1 with probability \\(p\\) and the value 0 with probability \\(1 - p\\). In our case, \\(p = \\frac{1}{2}\\) for a fair coin.\n\n\n\nAs mentioned above, we can also think about random variables with continuous values. For example, let \\(Y\\) be a random variable that represents the height of a person in centimeters. Let’s assume that every person’s height is equally likely to be between 150 cm and 200 cm (this is not true of course). The probability function for \\(Y\\) would be: \\[\nf(y) = \\P (Y = y) = \\begin{cases}\n    \\frac{1}{50} & \\text{if } 150 \\leq y \\leq 200 \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\n\n\n\nUniform random variable\n\n\n\n\n\nThe above is an example of a uniform random variable, which takes on values in a continuous range with equal probability. In our case, the range is from 150 cm to 200 cm, and the probability density function is \\(\\frac{1}{50}\\).\n\n\n\nIn statistics, we treat our data as a random variable (or a collection of random variables). What this means is that we assume that the data we observe is just one possible outcome of a random process.\nThis is a powerful assumption because it allows us to use probability theory to make inferences about the underlying process that generated the data. This is going to be a key idea in the next lecture and throughout the course.",
    "crumbs": [
      "Home",
      "Lecture 02: Probability and Random Variables"
    ]
  },
  {
    "objectID": "notebooks/lecture-02.html#probability-distributions-and-histograms",
    "href": "notebooks/lecture-02.html#probability-distributions-and-histograms",
    "title": "Lecture 02: Probability and Random Variables",
    "section": "Probability distributions and histograms",
    "text": "Probability distributions and histograms\nWe call the probability function for a random variable a probability distribution, which describes how the probabilities are distributed across the possible values of the random variable.\nDistributions can be discrete or continuous, depending on the type of random variable. For discrete random variables, the probability distribution is often represented as a probability mass function (PMF), which gives the probability of each possible value. For continuous random variables, the probability distribution is represented as a probability density function (PDF), which gives the density of probability at each point.\nLet’s say we have a random variable \\(X\\), but we don’t know the exact probability function. Instead, we have a set of observed data points \\(\\{x_1, x_2, \\ldots, x_n\\}\\) that we believe are individual realizations of \\(X\\). In other words, we have a sample of data that we think is representative of the underlying random variable.\nHow can we visualize this data to understand the distribution of \\(X\\)? The simplest solution is to just plot how many times each value occurs in the data. This is called a histogram.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.array([0, 0, 1, 1, 0])\n\nplt.hist(x, bins=2, density=False, alpha=0.5, color='blue', ec='k', label='Data')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\n\n\nText(0, 0.5, 'Frequency')\n\n\n\n\n\n\n\n\n\nThe histogram is a graphical representation that summarizes the",
    "crumbs": [
      "Home",
      "Lecture 02: Probability and Random Variables"
    ]
  },
  {
    "objectID": "notebooks/lecture-00.html",
    "href": "notebooks/lecture-00.html",
    "title": "Lecture 00",
    "section": "",
    "text": "So begins “Understanding Uncertainty”, a course in statistical thinking and data science.\nThis is lecture 0. See the syllabus for an overview of the course.\nOur basic goals for the course are:\n\nto build a strong intuition about data, where it comes from, and what questions it can answer.\nto learn the basic computational skills needed to manipulate and analyze data. Working with data also helps with (1)!",
    "crumbs": [
      "Home",
      "Lecture 00: Why Statistics?"
    ]
  },
  {
    "objectID": "notebooks/lecture-00.html#welcome",
    "href": "notebooks/lecture-00.html#welcome",
    "title": "Lecture 00",
    "section": "",
    "text": "So begins “Understanding Uncertainty”, a course in statistical thinking and data science.\nThis is lecture 0. See the syllabus for an overview of the course.\nOur basic goals for the course are:\n\nto build a strong intuition about data, where it comes from, and what questions it can answer.\nto learn the basic computational skills needed to manipulate and analyze data. Working with data also helps with (1)!",
    "crumbs": [
      "Home",
      "Lecture 00: Why Statistics?"
    ]
  },
  {
    "objectID": "notebooks/lecture-00.html#why-statistics",
    "href": "notebooks/lecture-00.html#why-statistics",
    "title": "Lecture 00",
    "section": "Why statistics?",
    "text": "Why statistics?\nStatistics is, essentially, the study of data and how to use it. People argue about the purpose of statistics, but basically you can do 3 things with data: (1) description, (2) inference, and (3) prediction.",
    "crumbs": [
      "Home",
      "Lecture 00: Why Statistics?"
    ]
  },
  {
    "objectID": "notebooks/lecture-00.html#description",
    "href": "notebooks/lecture-00.html#description",
    "title": "Lecture 00",
    "section": "Description",
    "text": "Description\nDescriptive statistics is the process of summarizing data. This can be done with numbers (e.g., mean, median, standard deviation) or with visualizations (e.g., histograms, boxplots). Descriptive statistics, importantly, are completely limited to the sample of data at hand.\nLet’s load in some data and take a look at it.\nThe dataset contains Airbnb listings in New York City, including prices, locations, and other features.\n\n\nCode\n# from https://www.kaggle.com/datasets/arianazmoudeh/airbnbopendata\n# import the data on Airbnb listings in the New York City\nairbnb = pd.read_csv(\"../data/airbnb.csv\")\n# data cleaning\nairbnb = airbnb.rename(columns={\"neighbourhood group\": \"borough\"})\nairbnb = airbnb.dropna(subset=[\"borough\", \"price\", \"long\", \"lat\"])\nairbnb[\"borough\"] = airbnb[\"borough\"].str.lower()\nairbnb[\"borough\"] = airbnb[\"borough\"].str.replace(\"manhatan\", \"manhattan\")\nairbnb[\"borough\"] = airbnb[\"borough\"].str.replace(\"brookln\", \"brooklyn\")\n# print column names\nprint(airbnb.columns.values)\n\n\n['id' 'NAME' 'host id' 'host_identity_verified' 'host name' 'borough'\n 'neighbourhood' 'lat' 'long' 'country' 'country code' 'instant_bookable'\n 'cancellation_policy' 'room type' 'Construction year' 'price'\n 'service fee' 'minimum nights' 'number of reviews' 'last review'\n 'reviews per month' 'review rate number' 'calculated host listings count'\n 'availability 365' 'house_rules' 'license']\n\n\n\n\nCode\n# print the first 5 rows\nairbnb[:5]\n\n\n\n\n\n\n\n\n\nid\nNAME\nhost id\nhost_identity_verified\nhost name\nborough\nneighbourhood\nlat\nlong\ncountry\n...\nservice fee\nminimum nights\nnumber of reviews\nlast review\nreviews per month\nreview rate number\ncalculated host listings count\navailability 365\nhouse_rules\nlicense\n\n\n\n\n0\n1001254\nClean & quiet apt home by the park\n80014485718\nunconfirmed\nMadaline\nbrooklyn\nKensington\n40.64749\n-73.97237\nUnited States\n...\n$193\n10.0\n9.0\n10/19/2021\n0.21\n4.0\n6.0\n286.0\nClean up and treat the home the way you'd like...\nNaN\n\n\n1\n1002102\nSkylit Midtown Castle\n52335172823\nverified\nJenna\nmanhattan\nMidtown\n40.75362\n-73.98377\nUnited States\n...\n$28\n30.0\n45.0\n5/21/2022\n0.38\n4.0\n2.0\n228.0\nPet friendly but please confirm with me if the...\nNaN\n\n\n2\n1002403\nTHE VILLAGE OF HARLEM....NEW YORK !\n78829239556\nNaN\nElise\nmanhattan\nHarlem\n40.80902\n-73.94190\nUnited States\n...\n$124\n3.0\n0.0\nNaN\nNaN\n5.0\n1.0\n352.0\nI encourage you to use my kitchen, cooking and...\nNaN\n\n\n3\n1002755\nNaN\n85098326012\nunconfirmed\nGarry\nbrooklyn\nClinton Hill\n40.68514\n-73.95976\nUnited States\n...\n$74\n30.0\n270.0\n7/5/2019\n4.64\n4.0\n1.0\n322.0\nNaN\nNaN\n\n\n4\n1003689\nEntire Apt: Spacious Studio/Loft by central park\n92037596077\nverified\nLyndon\nmanhattan\nEast Harlem\n40.79851\n-73.94399\nUnited States\n...\n$41\n10.0\n9.0\n11/19/2018\n0.10\n3.0\n1.0\n289.0\nPlease no smoking in the house, porch or on th...\nNaN\n\n\n\n\n5 rows × 26 columns\n\n\n\nNow there’s a lot you can do, but let’s start with a simple histogram of the price of listings.\n\n\nCode\n# format the price column\nairbnb['price'] = airbnb['price'].replace({'\\\\$': '', ',': ''}, regex=True).astype(float)\n# plot a histogram of the price column\nplt.figure(figsize=(10, 5))\nplt.hist(airbnb['price'], bins=50)\nplt.title('Price Distribution of Airbnb Listings in NYC')\nplt.xlabel('Price')\nplt.ylabel('Frequency')\n\n\nText(0, 0.5, 'Frequency')\n\n\n\n\n\n\n\n\n\nComputing statistics like the mean, standard deviation, and quartiles is easy.\n\n\nCode\nairbnb[\"price\"].describe()\n\n\ncount    102316.000000\nmean        625.291665\nstd         331.677344\nmin          50.000000\n25%         340.000000\n50%         624.000000\n75%         913.000000\nmax        1200.000000\nName: price, dtype: float64\n\n\nWe can even use specialized libraries to make use of the geographic information in the data. For example, we can use the geopandas library to plot the locations of listings on a map of New York City.\n\n\nCode\nimport geopandas as gpd\nfrom geodatasets import get_path\n# load the shapefile of NYC neighborhoods\nnyc_neighborhoods = gpd.read_file(get_path('nybb'))\nnyc_neighborhoods = nyc_neighborhoods.to_crs(epsg=4326)  # convert to WGS84\n# plot the neighborhoods with airbnb listings\nnyc_neighborhoods.plot(figsize=(8, 8), color='white', edgecolor='black')\n# plot the airbnb listings on top of the neighborhoods\n# use the 'long' and 'lat' columns to create a GeoDataFrame\nairbnb_gdf = gpd.GeoDataFrame(airbnb, geometry=gpd.points_from_xy(airbnb['long'], airbnb['lat']), crs='EPSG:4326')\n# set the coordinate reference system to WGS84\nairbnb_gdf.plot(ax=plt.gca(), column=\"price\", markersize=3, alpha=0.05, legend=True, cmap='viridis', legend_kwds={'shrink': 0.5, 'label': 'Price ($)'})\nplt.title('Airbnb Listings in NYC')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\n\n\n\n\nThere is a lot of information in the data, and we can summarize it in many different ways. But descriptive statistics only describe the data.\nWhy is this limiting? After all, we like data – it tells us things about the world and it’s objective and quantifiable.\nThe problem is that data is not always complete. In fact, it almost never is. And incomplete data can lead to misleading conclusions.\nLet’s look at our Airbnb data again. What if instead of looking at the entire dataset, we only looked at a small “sample” or subset of the data?\n\n\nCode\n# separately plot 3 samples of airbnb listings\nfig, ax = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\nax = ax.flatten()\nfor i in range(4):\n    # sample 1000 listings\n    sample = airbnb.sample(100, random_state=i)\n    # plot the neighborhoods with airbnb listings\n    nyc_neighborhoods.plot(ax=ax[i], color='white', edgecolor='black')\n    # plot the airbnb listings on top of the neighborhoods\n    # use the 'long' and 'lat' columns to create a GeoDataFrame\n    airbnb_gdf_sample = gpd.GeoDataFrame(sample, geometry=gpd.points_from_xy(sample['long'], sample['lat']), crs='EPSG:4326')\n    # set the coordinate reference system to WGS84\n    airbnb_gdf_sample.plot(ax=ax[i], column=\"price\", markersize=3, alpha=0.8, legend=True, cmap='viridis', legend_kwds={'shrink': 0.5, 'label': 'Price ($)'})\n    ax[i].set_title(f'Airbnb Listings in NYC (Sample {i+1})\\n Average Price: ${sample[\"price\"].mean():.2f}')\n    ax[i].set_xlabel('Longitude')\n    ax[i].set_ylabel('Latitude')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nNotice how the samples differ from one another. They have different geography and different prices. This means you can’t just look at the descriptive statistics of a single sample and draw conclusions about the entire population.\n\n\n\n\n\n\nSample vs. Population\n\n\n\n\n\nA population is the entire set of data that you are interested in. A sample is a subset of a population. For example, if you are interested in the average price of all Airbnb listings in New York City, then the population is all of those listings. A sample would be a smaller subset of those listings, which may or may not be representative of the entire population.\nNote that this definition is flexible. For example, if you are interested in the average price of all short-term rentals in New York City, then the population is all rentals. Even an exhaustive list of Airbnb listings would just be a sample from that population.\nOften, the population is actually more abstract or theoretical. For example, if you are interested in the average price of all possible Airbnb listings in New York City, then the population includes all potential listings, not just the ones that currently exist.\n\n\n\nDescriptive statistics are useful for understanding the data at hand, but they don’t necessarily tell us much about the world outside of the data. For that, we need to do something more.",
    "crumbs": [
      "Home",
      "Lecture 00: Why Statistics?"
    ]
  },
  {
    "objectID": "notebooks/lecture-00.html#inference",
    "href": "notebooks/lecture-00.html#inference",
    "title": "Lecture 00",
    "section": "Inference",
    "text": "Inference\nSo what if we want to answer questions about a population based on a sample? This is where inference comes in. Specifically, we want to use the given sample to infer something about the population.\nHow do we do this if we can’t ever see the entire population? The answer is that we need a link which connects the sample to the population – specifically, we can explicitly treat the sample as the outcome of a data-generating process (DGP).\n\n\n\n\n\n\nThere is always a DGP\n\n\n\n\n\nA data-generating process (DGP) is a theoretical construct that describes how data is generated in a population. It encompasses all the factors that influence the data, including the underlying mechanisms and relationships between variables.\nThere has to be a DGP, even if we don’t know what it is. The DGP is the process that generates the data we observe.\nThe full, true DGP is usually unknown. However, we can make assumptions about it and use those assumptions to draw inferences about the population (in the case that our assumptions are correct).\n\n\n\nOf course, we don’t necessarily know what the DGP is. If we we knew everything about how the data was generated, we probably would not have any questions to ask in the first place!\nThis is where the model comes in. A model is a simplified mathematical representation of the DGP that allows us to make inferences about the population based on the sample. At the end of the day, a model is sort of a guess – a guess about where your data come from.\n\n\n\n\n\n\nAll models are wrong\n\n\n\n\n\nThere is a very famous and oft-cited quote by George Box, a statistician, that goes:\n\n“All models are wrong, but some are useful.”\n\nThis means that all mathematical models are simplifications of reality, and they will never perfectly capture the true DGP. However, some models can still be useful for making predictions or drawing inferences about the population. We will talk more about this and see examples throughout the course.\n\n\n\n\nA simple model\nWe’ll talk about probability distributions in more detail later in the course, but for now let’s just say that a probability distribution is a mathematical function that describes the likelihood of different outcomes in a random process.\nThe most basic example is a coin flip. If we flip a fair coin, there are two possible outcomes: heads or tails. The probability of each outcome is 0.5, so we can represent this with a simple probability distribution.\n\\[\\begin{equation}\nP(X) = \\begin{cases}\n0.5 & \\text{if } X = \\text{heads} \\\\\n0.5 & \\text{if } X = \\text{tails} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\end{equation}\\]\n\n\nCode\n# average price per borough\nborough_price = airbnb.groupby('borough')['price'].count().reset_index()\n# plot the average price per borough\nplt.figure(figsize=(10, 5))\nplt.bar(borough_price['borough'], borough_price['price'])\nplt.title('Number of Airbnb Listings per Borough')\nplt.xlabel('Borough')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nairbnb_gdf.plot(column=\"neighbourhood group\")\nplt.title('Airbnb Listings in NYC by borough')\n\n\nText(0.5, 1.0, 'Airbnb Listings in NYC by borough')",
    "crumbs": [
      "Home",
      "Lecture 00: Why Statistics?"
    ]
  },
  {
    "objectID": "notebooks/lecture-00.html#prediction",
    "href": "notebooks/lecture-00.html#prediction",
    "title": "Lecture 00",
    "section": "Prediction",
    "text": "Prediction\nPrediction is the process of using a model to make predictions about unseen (or future) data.\nTake \\(X \\sim \\text{Uniform}(0, 1)\\)\n\n\nCode\nx = np.random.uniform(0, 1, 1000)\n\nplt.hist(x, bins=20, edgecolor=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuick exercise",
    "crumbs": [
      "Home",
      "Lecture 00: Why Statistics?"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "understanding-uncertainty",
    "section": "",
    "text": "This website contains course materials for the Understanding Uncertainty course, which is a part of the US-Israel Academic Bridge Fellowship hosted at the University of Pennsylvania.\n\n\n\nSomething from DALL-E’s imagination"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Assignment\nDescription\nDue Date\n\n\n\n\nAssignment 1"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Course Title: Understanding Uncertainty: An Introduction to Statistics through Data Generating Processes and Computational Simulations\nCourse Schedule: 4 Weeks, 3 sessions per week, 1.5 hours per session\n\n\n\n\n\n\n\n\n\nWeek\nSession\nTopics Covered\nActivities/Assignments\n\n\n\n\n1\nSession 1\n- Course Introduction- Understanding Data Generating Processes (DGPs)- Basic Python Syntax and Data Types\n- Install Python and Jupyter- Assignment: Write a simple Python program\n\n\n\nSession 2\n- Data Structures in Python (Lists, Tuples, Dictionaries)- Importing and Exporting Data- Generating Random Numbers\n- Load and explore datasets- Assignment: Simulate a simple DGP\n\n\n\nSession 3\n- Descriptive Statistics- Measures of Central Tendency and Variability- Data Visualization with Matplotlib and Seaborn\n- Plot histograms and boxplots- Assignment: Analyze summary statistics of a dataset\n\n\n2\nSession 4\n- Probability Concepts- Discrete and Continuous Distributions- Simulating Random Events\n- Simulate coin tosses and dice rolls- Assignment: Probability simulations\n\n\n\nSession 5\n- Exploring Different Distributions- Normal, Binomial, Poisson, Exponential Distributions- Central Limit Theorem (CLT)\n- Visualize distributions and CLT demonstrations- Assignment: CLT simulation project\n\n\n\nSession 6\n- Understanding Uncertainty- Confidence Intervals- Margin of Error- Introduction to Hypothesis Testing\n- Calculate confidence intervals- Assignment: Formulate and test hypotheses\n\n\n3\nSession 7\n- Resampling Methods- Bootstrapping and Permutation Tests- Practical Applications\n- Conduct bootstrap and permutation tests- Assignment: Resampling project\n\n\n\nSession 8\n- Bias and Variance Trade-off- Overfitting and Underfitting- Model Complexity and Generalization\n- Visualize bias-variance trade-off- Assignment: Experiment with model complexity\n\n\n\nSession 9\n- Introduction to Machine Learning- Supervised vs. Unsupervised Learning- Training and Testing Sets- Evaluation Metrics\n- Split data and evaluate models- Assignment: Build and evaluate predictive models\n\n\n4\nSession 10\n- Regularization Techniques- Ridge and Lasso Regression- Fairness in Machine Learning\n- Implement regularization- Assignment: Regularization and fairness assessment\n\n\n\nSession 11\n- Population Statistics and Representation- Sampling Methods and Sampling Bias- Ethical Considerations in Data Science\n- Simulate sampling strategies- Assignment: Design a fair sampling plan\n\n\n\nSession 12\n- Course Review and Future Directions- Student Project Presentations- Trends in Statistics and Data Science\n- Present final projects- Course Feedback Survey"
  },
  {
    "objectID": "notebooks/lecture-01.html",
    "href": "notebooks/lecture-01.html",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "",
    "text": "This lecture will be, intentionally, a bit of a whirlwind. That’s because with the advent of large language models (LLMs) like ChatGPT, Claude, Gemini, etc. knowing how to program in specific languages like Python is becoming less important. You don’t need that much practice or to focus on the syntax of a specific language.\nInstead, the important thing is to understand the core concepts involved in programming, which are largely universal across languages. This high-level understanding will allow you to use LLMs effectively to write code in any language, including Python. If you don’t understand the concepts, you won’t be able to identify when the LLM is making mistakes or producing suboptimal code.",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#variables-and-types",
    "href": "notebooks/lecture-01.html#variables-and-types",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Variables and types",
    "text": "Variables and types\nVariables are used to store data in a program. They can hold different types of data, such as numbers, strings (text), lists, and more.\n\n\n\n\n\n\nFunctions act on variables\n\n\n\nFunctions in programming are designed to operate on variables. They take input (variables), perform some operations, and return output. Understanding how variables work is crucial for effectively using functions.\nWe’ll explore functions in more detail later (Functions), but for now, remember that functions are named blocks of code that manipulate variables to achieve specific tasks.\nSome functions are built-in, meaning they are provided by the programming language itself, while others can be defined by the user. Built-in functions in Python include print() for displaying output, as well as type() for checking the type of a variable.\n\n\nIt is both useful and pretty accurate to think of programmatic variables in the same way you think of algebraic variables in math. You can assign or change the value of a variable, and you can use it in calculations or operations.\nYou can create a variable by assigning it a value using the equals sign (=).\nFor example, if you create a variable x that holds the value 5, you can use it in calculations like this:\nx = 5\ny = x + 3\nprint(y)  # Output: 8\nThe following table describes some common variable types:\n\n\n\n\n\n\n\nVariable Type\nDescription\n\n\n\n\nInteger\nWhole numbers, e.g., 5, -3, 42\n\n\nFloat\nDecimal numbers, e.g., 3.14, -0.001, 2.0\n\n\nString\nTextual data, e.g., \"Hello, world!\", 'Python'\n\n\nList\nOrdered collection of items, e.g., [1, 2, 3], ['a', 'b', 'c']\n\n\nDictionary\nKey-value pairs, e.g., {'name': 'Alice', 'age': 30}\n\n\nBoolean\nTrue or False values, e.g., True, False\n\n\n\nLet’s discuss a few important ones in more detail\n\n\n\n\n\n\nEverything is an object\n\n\n\nIn Python, everything is an object. This means that even basic data types like integers and strings are treated as objects with methods and properties. For example, you can call methods on a string object to manipulate it, like my_string.upper() to convert it to uppercase.\nSee the later section on Object-Oriented Programming for more details.",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#lists",
    "href": "notebooks/lecture-01.html#lists",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Lists",
    "text": "Lists\nWe often need to store multiple values together. The most basic way to achieve this is with a list. A list is an ordered collection of items that can be of any type, including other lists. “Ordered” means that the items have a specific sequence, and you can access them by their position (index) in the list.\nIn Python, you can create a list using square brackets []. For example:\n\nmy_list = [1, 2, 3, 'apple', 'banana']\nprint(my_list[0])  # Output: 1\n\n1\n\n\nYou can access items in a list using their index (a number specifying their position). In Python, indexing starts at 0, so my_list[0] refers to the first item in the list.\nYou can also modify lists by adding or removing items. For example:\n\nmy_list.append('orange')  # Adds 'orange' to the end of the list\nprint(my_list)  # Output: [1, 2, 3, 'apple', 'banana', 'orange']\n\n[1, 2, 3, 'apple', 'banana', 'orange']",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#arrays-numpy",
    "href": "notebooks/lecture-01.html#arrays-numpy",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Arrays (NumPy)",
    "text": "Arrays (NumPy)\nWhile lists are flexible, they can be inefficient and unreliable for many numerical operations. Arrays, provided by the core library numpy, enforce a single data type and are optimized for numerical computations. They also have lots of built-in functionality for mathematical operations.\nYou can create a NumPy array using the numpy.array() function. For example:\nimport numpy as np\nmy_array = np.array([1, 2, 3, 4, 5])\nprint(my_array)  # Output: [1 2 3 4 5]\nYou can perform mathematical operations on NumPy arrays, and they will be applied element-wise. For example:\nmy_array = np.array([1, 2, 3, 4, 5])\nmy_array_squared = my_array ** 2\nprint(my_array_squared)  # Output: [ 1  4  9 16 25]\nYou can’t have mixed data types in a NumPy array, so if you try to create an array with both numbers and strings, it will convert everything to strings:\nmixed_array = np.array([1, 'two', 3.0])\nprint(mixed_array)  # Output: ['1' 'two' '3.0']",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#dictionaries",
    "href": "notebooks/lecture-01.html#dictionaries",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Dictionaries",
    "text": "Dictionaries\nSometimes a list or array is not enough. You may want to store data in a way that allows you to access it by a keyword rather than by an index. For example, I might have a list of people and their ages, but I want to be able to look up a person’s age by their name. In this case, I can use a dictionary.\nWe can create a dictionary using curly braces {} and separating keys and values with a colon :. Here’s an example:\n\nname_age_dict = {\n    \"Alice\": 30,\n    \"Bob\": 25,\n    \"Charlie\": 35\n}\n\nIn order to access a value in a dictionary, we use the key in square brackets []. Here’s how you can do that:\n\nname_age_dict[\"Bob\"] # this will print Bob's age\n\n25\n\n\nThe “value” in a dictionary can be of any type, including another dictionary or a list. This allows for building up complex data structures that contain named entities and their associated data.\nFor example, you might have a dictionary that contains different types of data about a person.\n\nname_age_list_dict = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n}",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#dataframes",
    "href": "notebooks/lecture-01.html#dataframes",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Dataframes",
    "text": "Dataframes\nMost of the time, data scientists work with tabular data (data organized in tables with rows and columns). Think of the data you typically see in spreadsheets – rows represent individual records, and columns represent attributes of those records.\nIn Python, the most common way to work with tabular data is through the pandas library, which provides a powerful data structure called a DataFrame.\n\n\nCode\nimport pandas as pd\n# Create a DataFrame with sample data\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'Height (cm)': [165, 180, 175],\n    'Weight (kg)': [55.1, 80.5, 70.2],\n    'City': ['New York', 'Los Angeles', 'Chicago']\n})\ndf\n\n\n\n\n\n\n\n\n\nName\nAge\nHeight (cm)\nWeight (kg)\nCity\n\n\n\n\n0\nAlice\n25\n165\n55.1\nNew York\n\n\n1\nBob\n30\n180\n80.5\nLos Angeles\n\n\n2\nCharlie\n35\n175\n70.2\nChicago\n\n\n\n\n\n\n\nOne import thing to realize about DataFrames that each column can have a different data type. For example, one column might contain integers, another might contain strings, and yet another might contain floating-point numbers.\nHowever, all the values in a single column should be of the same type. Intuitively: since columns represent attributes, every value in a column should represent the same kind of information. It wouldn’t make sense if the “city” column of a DataFrame contained both “New York” (a string) and 42 (an integer).\nNote that this rule isn’t necessarily enforced by the DataFrame structure itself, but it’s a good practice to follow. Otherwise, you might run into issues when performing operations on the DataFrame.\n\n\nCode\nbad_df = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 'Thirty-Five'],  # Mixed types in the 'Age' column\n})\n\nbad_df[\"Age\"] * 3\n\n\n0                                   75\n1                                   90\n2    Thirty-FiveThirty-FiveThirty-Five\nName: Age, dtype: object",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#conditional-logic",
    "href": "notebooks/lecture-01.html#conditional-logic",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Conditional logic",
    "text": "Conditional logic\nConditional logic allows you to make decisions in your code based on certain conditions. This is essential for controlling the flow of your program and executing different actions based on different situations.\n\nIf-elif-else statements\nThe most common way to implement conditional logic is through if, elif, and else statements:\n\n\n\n\n\n\n\nStatement Type\nDescription\n\n\n\n\nif\nChecks a condition and executes the block if it’s true.\n\n\nelif\nChecks another condition if the previous if or elif was false.\n\n\nelse\nExecutes a block if all previous conditions were false.\n\n\n\nHere’s an example of how to use these statements. Play around with the code below to see how it works. You can change the value of age to see how the output changes based on different conditions.\n\n\n\n\n\n\nNote that the elif and else statements are optional. You can have just an if statement, which will execute a block of code if the condition is true and skip it if the condition is false.\n\n\n\n\n\n\nBoolean expressions\n\n\n\n\n\nBoolean expressions are conditions that evaluate to either True or False. They are often used in if statements to control the flow of the program. Common operators for creating Boolean expressions include:\n\n\n\nOperator\nDescription\n\n\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n&lt;\nLess than\n\n\n&lt;=\nLess than or equal to\n\n\n&gt;\nGreater than\n\n\n&gt;=\nGreater than or equal to\n\n\nand , &\nLogical AND\n\n\nor, |\nLogical OR\n\n\nnot , ~\nLogical NOT",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#loops",
    "href": "notebooks/lecture-01.html#loops",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Loops",
    "text": "Loops\nLoops are special constructs that allow you to repeat a block of code multiple times in sequence. They are useful when you want to perform the same operation on multiple items, such as iterating over a list or processing each row in a DataFrame.\nThe two most common types of loops are for loops and while loops.\n\nFor Loops\nA for loop iterates over a sequence (like a list or a string) and executes a block of code for each item in that sequence. Here’s an example:\nmy_list = [1, 2, 3, 4, 5]\nfor item in my_list:\n    print(item)\nThis will print each item in my_list one by one.\n\n\n\n\n\n\nUseful Python functions: range() and enumerate()\n\n\n\nIn Python, the range() function generates a sequence of numbers, which is often used in for loops. For example, range(5) generates the numbers 0 to 4. The enumerate() function is useful when you need both the index and the value of items in a list. It returns pairs of (index, value) for each item in the list. For example:\nmy_list = ['a', 'b', 'c']\nfor index, value in enumerate(my_list):\n    print(f\"Index: {index}, Value: {value}\")\n\n\n\n\nWhile Loops\nA while loop continues to execute a block of code as long as a specified condition is true. Here’s an example:\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1 # Increment the count\nThis will print the numbers 0 to 4, incrementing count by 1 each time until the condition count &lt; 5 is no longer true.",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#functions-and-functional-programming",
    "href": "notebooks/lecture-01.html#functions-and-functional-programming",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Functions and functional programming",
    "text": "Functions and functional programming\nFunctions are reusable blocks of code that perform a specific task. They allow you to organize your code into logical sections, making it easier to read, maintain, and reuse.\nThey work like functions in math: you can pass inputs (arguments) to a function, and it will return an output (result). You can define a function in Python using the def keyword, followed by the function name and parentheses containing any parameters. Here’s an example:\ndef add_numbers(a, b):\n    \"\"\"Adds two numbers and returns the result.\"\"\"\n    return a + b\nresult = add_numbers(3, 5)\nprint(result)  # Output: 8\nFunctions can also have default values for parameters, which allows you to call them with fewer arguments than defined. For example:\ndef greet(name=\"World\"):\n    \"\"\"Greets the specified name or 'World' by default.\"\"\"\n    return f\"Hello, {name}!\"\nprint(greet())          # Output: Hello, World!\nprint(greet(\"Alice\"))  # Output: Hello, Alice!\nFunctional programming is a style of programming that treats computer programs as the evaluation of mathematical functions. It is alternatively called value-oriented programming1 because the output of a program is just the value(s) it produces as a function of its inputs.\nProbably the core principle of functional programming is to avoid changing state and mutable data. This means that once a value is created, it should not be changed. Instead, you create new values based on existing ones.\nThat means means that functions should not have side effects – they use data passed to them and return a new value without modifying the input data. This makes it easier to reason about code, as you can understand what a function does just by looking at its inputs and outputs.\nFor example, consider the following two functions for squaring a number:\n\n\nCode\nimport numpy as np\n\ndef square_functional(input):\n    \"\"\"Returns the square of an array\"\"\"\n    return input ** 2\n\ndef square_side_effect(input):\n    \"\"\"Returns the square of an array with a side effect\"\"\"\n    input[0] = -1\n    return input ** 2  # This is a side effect, modifying the first element of input\n\na = np.array([1, 3, 5])\nb = square_functional(a)  # b will be 25, a remains 5\nprint(f\"Functional: a = {a}, b = {b}\")\nc = square_side_effect(a)  # c will be 25, a will still be 5\nprint(f\"Side Effect: a = {a}, c = {c}\")\n\n\nFunctional: a = [1 3 5], b = [ 1  9 25]\nSide Effect: a = [-1  3  5], c = [ 1  9 25]\n\n\nThere are somewhat complicated rules about what objects can be modified in place and what cannot (sometimes Python allows it, sometimes it doesn’t), but the general rule is that you should avoid modifying objects in place unless you have a good reason to do so. The main reason is that you might inadvertently change the value of an object that is being used elsewhere in your code, leading to bugs that are hard to track down. Instead, create new objects based on existing ones.",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#object-oriented-programming",
    "href": "notebooks/lecture-01.html#object-oriented-programming",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Object-Oriented Programming",
    "text": "Object-Oriented Programming\nWhile you can write programs in Python using just functions, the language is really designed for object-oriented programming (OOP). OOP is a style of programming built around the concept of “objects”, which are specific instances of classes.\nA class is like a template for creating new objects. It defines the properties (attributes) and \\ behaviors (methods) that the objects created from the class will have.\nTo define a class in Python, you use the class keyword followed by the class name. Every class should have an __init__ method, which is a special method that initializes the object when it is created.\nHere’s a simple example of a class:\n\n\nCode\nclass Date():\n    \"\"\"A simple class to represent a date\"\"\"\n\n    # This is the constructor method, called when an instance is created like Date(2025, 5, 6)\n    def __init__(self, year, month, day):\n        self.year = year\n        self.month = month\n        self.day = day\n\n    def __str__(self):\n        # defined what print() should do\n        # formats the date as YYYY-MM-DD\n        return f\"{self.year:04d}-{self.month:02d}-{self.day:02d}\"\n    \n    # here is a method that checks if the date is in summer\n    def is_summer(self):\n        \"\"\"Check if the date is in summer (June, July, August)\"\"\"\n        return self.month in [6, 7, 8]\n\n# Create an instance of the Date class\ndate_instance = Date(2025, 5, 6)\n\nprint(date_instance)  # Output: 2025-05-06\nprint(date_instance.is_summer())  # Output: False\n\n\n2025-05-06\nFalse\n\n\nObject-oriented programming has a number of advantages, but many of them are really just about organizing code in a way that makes it easier to understand, reuse, and maintain.\nOne of the key features of OOP is inheritance, which allows you to create new classes based on existing ones. This means you can define a base class with common attributes and methods, and then create subclasses that inherit from it and add or override functionality.\nFor example, you might inherit from the base class Date to create a subclass HolidayDate that adds specific attributes or methods related to holidays:\n\n\n\n\n\n\n\n\nclass HolidayDate(Date):\n    def __init__(self, year, month, day, holiday_name):\n        super().__init__(year, month, day)\n        self.holiday_name = holiday_name\n\n    def print_holiday(self):\n        print(f\"{self.holiday_name} is on {self}.\")\n\nThis allows you to create specialized versions of a class without duplicating code, making your codebase cleaner and easier to maintain.\nFor the purposes of statistics and data science, classes are mostly useful because they allow you to create custom data structures that can hold both data and methods for manipulating that data. We have already seen this in the context of DataFrames – the pandas library defines a DataFrame class that has methods for manipulating tabular data. By defining and using DataFrame objects, you get access to a wide range of functionality for working with data without having to implement it yourself. For example, you can filter rows, group data, and perform aggregations (like mean, sum, etc.) using methods defined in the DataFrame class.",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#summary",
    "href": "notebooks/lecture-01.html#summary",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Summary",
    "text": "Summary\nIn this lecture we covered some of the core programming concepts that are important to understand when working with Python or any other programming language. In today’s assignment, you will practice these concepts by writing Python code to solve some problems.",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-01.html#footnotes",
    "href": "notebooks/lecture-01.html#footnotes",
    "title": "Lecture 01: Programming Basics, Data Structures, and Data Manipulation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTechnically there is a difference between functional programming and value-oriented programming that programming-language nerds care about, but for our purposes, they are the same thing.↩︎",
    "crumbs": [
      "Home",
      "Lecture 01: Programming Basics"
    ]
  },
  {
    "objectID": "notebooks/lecture-10.html",
    "href": "notebooks/lecture-10.html",
    "title": "Lecture 10: ANOVA",
    "section": "",
    "text": "We want to emphasize that nearly any statistical method with a closed-form solution can be replicated with a simulation.\nTake ANOVA, or analysis of variance, for example. The ANOVA test is used to determine whether there are any statistically significant differences between the means of two or more groups. It is a parametric test that assumes the data is normally distributed and that the variances of the groups are equal.\nThe exact test we compute is the F-test, which compares the variance between groups to the variance within groups. The null hypothesis is that all group means are equal, while the alternative hypothesis is that at least one group mean is different. The F-test relies on the fact that the ratio of two independent chi-squared variables (i.e. a normal variable, squared) follows an F-distribution.\nHere we will simulate the F-test by generating random data from a normal distribution and computing the F-statistic for different group means. We will see that under the null hypothesis (group means are equal), the F-statistic follows an F-distribution with degrees of freedom equal to the number of groups minus one and the total number of observations minus the number of groups.\nIn the next lecture we will compare the F-test to a non-parametric permutation test, which does not make any assumptions about the distribution of the data.",
    "crumbs": [
      "Home",
      "Lecture 10: Classification"
    ]
  }
]